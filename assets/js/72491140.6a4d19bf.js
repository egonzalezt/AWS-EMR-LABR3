"use strict";(self.webpackChunkaws_emr_labr_3=self.webpackChunkaws_emr_labr_3||[]).push([[7519],{1249:function(e){e.exports=JSON.parse('{"blogPosts":[{"id":"welcome","metadata":{"permalink":"/AWS-EMR-LABR3/blog/welcome","editUrl":"https://github.com/egonzalezt/AWS-EMR-LABR3/tree/main/blog/2021-08-26-welcome/index.md","source":"@site/blog/2021-08-26-welcome/index.md","title":"Welcome","description":"Hadoop HDFS","date":"2021-08-26T00:00:00.000Z","formattedDate":"August 26, 2021","tags":[{"label":"facebook","permalink":"/AWS-EMR-LABR3/blog/tags/facebook"},{"label":"hello","permalink":"/AWS-EMR-LABR3/blog/tags/hello"},{"label":"docusaurus","permalink":"/AWS-EMR-LABR3/blog/tags/docusaurus"}],"readingTime":1.29,"truncated":false,"authors":[{"name":"Esteban Gonzalez Tamayo","title":"Eafit University Student","url":"https://github.com/egonzalezt","imageURL":"https://github.com/egonzalezt.png","key":"esteban"},{"name":"ST0263","title":"Special topics in telematics","url":"https://github.com/ST0263","imageURL":"https://github.com/ST0263.png","key":"ST0263"}],"frontMatter":{"slug":"welcome","title":"Welcome","authors":["esteban","ST0263"],"tags":["facebook","hello","docusaurus"]}},"content":"![Hadoop HDFS](./Hadoop.png)\\n\\nThis lab was made for the University Subjet ST0263 following the guidelines below.\\n\\n\\nST0263 SPECIAL TOPICS IN TELEMATICS, 2022-1\\n\\nLAB 1: MANAGEMENT OF FILES IN HDFS AND S3 FOR BIG DATA\\n\\n1. Maximum delivery date: Saturday May 28 2022\\n\\n2. Individual work, each student must answer for these activities.\\n\\n3. Follow the github [guidelines](https://github.com/ST0263/st0263-2022-1/tree/main/Big%20Data/01-hdfs)\\n\\nDO THE PROPOSED ACTIVITIES IN:\\n\\n\\n4. It will document the creation of an EMR cluster (see videos previously sent), it will activate HUE, remember that you must create a \'hadoop\' user with the key you like.\\n\\nthey must also connect via shell (ssh) to the master node of the EMR cluster, where you will perform the HDFS CLI activities\\n\\nIn this cluster you should do:\\n\\n* Copy (manage) files to HDFS via HUE.\\n\\n* Copy (manage) files to HDFS via SSH.\\n\\nRemember that this HDFS data is ephemeral or temporary and is deleted when the cluster is deleted.\\n\\n* Copy (manage) files to AWS S3 via HUE.\\n\\n* Copy (manage) files to AWS S3 via SSH.\\n\\n\\n6. Each student, individually, must complete these labs, in the case of EMR, if someone does not have an account, they can use a common EMR and perform the separation in hdfs directories or AWS S3 buckets.\\n\\nRegarding the S3 buckets, they must be public reading (a simple google query: aws s3 public access, will give you the tips to achieve it).\\n\\nThis lab1 report must be sent by email from Interactiva Virtual, explicitly specifying the URL of the public bucket where the work datasets are."}]}')}}]);